export default [
	{
		timeslot: 'Typedesign with Karlo',
		title: 'Markus Mau (Hochschule Mainz)',
		description: `Generative AI models like Dalle, Midjourney, or Stable-Diffusion are increasingly making their
        mark in our design practice. In this workshop, we want to apply such innovative AI tools to
        the field of typography. Does the technology offer a new visual language? How does the
        design process change, and what opportunities does this offer for creative practice?
        Together, we will explore these and many other questions in the workshop. You will work
        hands-on with "intelligent tools" and develop your own typeface in collaboration with the
        Karlo AI model.`
	},
	{
		timeslot: 'Making (Non)Sense – Prototyping AI based Interactive Systems with Sensors',
		title: 'Rahel Flechtner (HfG Schwäbisch-Gmünd) & Jakob Kilian (KISD)',
		description: `In this workshop, we will explore the possibilities of sensor data and gain a deeper understanding
        of how it can be used to create interactive AI based systems.
        In the first part of the workshop, we'll be acting out AI systems in an interactive and playful
        manner, allowing you to gain insights into how these systems extract valuable information from
        data. This will be followed by a more practical part in which you'll learn how to prototype and
        train your own AI-based interactive systems. But this isn't just any interactive system! Inspired by
        the iconic Rube Goldberg machine, we'll be experimenting with a range of inputs and outputs to
        create playful interactions through the concatenation of everyday objects, sensors, and
        microcontrollers.`
	},
	{
		timeslot: 'PLAYTRACING',
		title: 'Simon Maris (Hochschule Trier)',
		description: `The process of visualising products, interiors, buildings and urban situations is
        about to change radically. Traditionally, render engines have been concerned
        with simulating the physical behaviour of light by bouncing rays of light through
        a virtual model. This requires creating accurate 3D digital models, texturing them,
        adding light sources and more. Now, machine learning systems are introducing
        a very different workflow. While models such as *stable diffusion* alone do not offer
        much control over the outcome, more recently plug-ins and other models with
        various input controls are entering the scene.
        We will explore these new workflows through playful experimentation,
        effortlessly blending and switching between the physical and digital worlds,
        combining multiple software tools and traditional modelling. It is all about
        discovering and enabling more spontaneity, and ultimately allowing more time
        to focus on composition, lighting, mood and attention to detail. Let's discover a
        new research tool and communicate our ideas, bring your own models, software,
        image making tools and visions!`
	},
	{
		timeslot: 'Designing Prompts',
		title: 'Benedikt Groß (HfG Schwäbisch-Gmünd)',
		description: `Prompting is a powerful method for generating images using AI image generators. By providing a textual description of an image, a prompt can guide the generator to create a visual representation of that description. However, crafting an effective prompt requires understanding the capabilities and limitations of these generators and even more important, the nuances of language that can impact how the generator interprets the prompt. In this course, we will explore how to create prompts for AI image generators, and how to use them to generate imaginative and compelling visuals. To get started, we will be working on a short project called "The Illustrated Thing from the Future", where you will create a prompt that describes an imaginary object or concept from the future, and use an AI image generator to bring it to life.
            Course content:
            - How do AI image generators / AI text-to-image systems work (roughly)?
            - How are prompts designed / how are prompts structured?
            - How to find the needle (desired image) in the haystack (latent space)?
            - What AI image generator tools are available?
            - Which models are suitable for which application?
            - Outlook: How can own models be trained?
            - Outlook: What other possibilities are there?
            - Perspective: What do these systems mean for us as designers?
            - Perspective: Art direction. How to deal with the flood of images?
            - Perspective: ethical considerations and legal problems of these systems.
            Students learn the potential of AI image generators with tangible examples. Students learn "prompting" as a method and can translate their design ideas into prompts. Students will be able to apply AI text-to-image systems to their design projects in the future.
            `
	}
];
